{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304b0c06",
   "metadata": {},
   "source": [
    "# Machine Learning Fundamentals - Lecture 03\n",
    "\n",
    "This is the Jupyter notebook for Lecture 03 of the Machine Learning Fundamentals\n",
    "course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0caaa45",
   "metadata": {},
   "source": [
    "## Part 1: Load and clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f40c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries using the commonly use short names (pd, sns, ...)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# The Path object from pathlib allows us to easily build paths in an\n",
    "# OS-independent fashion\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the required scikit-learn classes and functions\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Set a nicer style for Seaborn plots\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b4f293",
   "metadata": {},
   "source": [
    "## Part 1: load and clean the Pokémon dataset\n",
    "\n",
    "Here we just repeat the steps already done in the previous lectures, but in a\n",
    "more succint way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "761fb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (note the use of the Path object)\n",
    "df = pd.read_csv(Path(\"..\", \"datasets\", \"Pokemon.csv\"))\n",
    "\n",
    "# It's not good practice to have column names with spaces and other non-standard\n",
    "# characters, so let's fix this by renaming the columns to standard names\n",
    "df.rename(columns={\n",
    "    \"Type 1\" : \"Type1\",\n",
    "    \"Type 2\" : \"Type2\",\n",
    "    \"Sp. Atk\" : \"SpAtk\",\n",
    "    \"Sp. Def\" : \"SpDef\",\n",
    "}, inplace=True)\n",
    "\n",
    "# Replace missing values in the \"Type2\" column with the string \"None\"\n",
    "df[\"Type2\"] = df[\"Type2\"].fillna(\"None\")\n",
    "\n",
    "# Since primary and secondary types are essentially categories (and not just\n",
    "# strings / objects), we can convert these columns to the category type\n",
    "df[\"Type1\"] = df[\"Type1\"].astype(\"category\")\n",
    "df[\"Type2\"] = df[\"Type2\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07466c93",
   "metadata": {},
   "source": [
    "Before we proceed to the interesting part, we'll perform our data scaling and\n",
    "train/test data splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "41193ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use all features except the Total, which can be considered redundant\n",
    "# since it's the total of the other features\n",
    "features = [\"HP\", \"Attack\", \"Defense\", \"SpAtk\", \"SpDef\", \"Speed\"]\n",
    "\n",
    "# Get only the specified features\n",
    "df_X = df[features]\n",
    "\n",
    "# Standardize them\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(df_X)\n",
    "\n",
    "# Our labels will be the legendary status\n",
    "y = df[\"Legendary\"].to_numpy()\n",
    "\n",
    "# Let's split our data into training (80%) and test (20%) sets\n",
    "# Change the random_state parameter do split data in different ways\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "34e3762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = euclidean_distances(X_test, X_train)\n",
    "k = 5\n",
    "idx_mink = np.argpartition(dists, k, axis=1)[:, :k]\n",
    "\n",
    "labels_mink = y_train[idx_mink]\n",
    "\n",
    "maj_labels = np.zeros(labels_mink.shape[0], dtype=np.bool)\n",
    "for i, row in enumerate(labels_mink):\n",
    "    values, counts = np.unique(row, return_counts=True)\n",
    "    maj_labels[i] = values[np.argmax(counts)]\n",
    "\n",
    "# modes = np.array(modes)\n",
    "\n",
    "#neighs\n",
    "#idx_mink #.shape\n",
    "#y_train[idx_mink]\n",
    "#maj_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648147a5",
   "metadata": {},
   "source": [
    "## Part 2: Implement our own $k$-Nearest Neighbors classifier and regressor\n",
    "\n",
    "We'll use our implementation to classify legendary and non-legendary Pokémons,\n",
    "and use it as a regressor to predict the \"Total\" column.\n",
    "\n",
    "We'll also compare our results with the respective classifier and regressor\n",
    "available in `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d5e84192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict(X_train, y_train, X_test, k=5, task=\"class\"):\n",
    "\n",
    "    dists = euclidean_distances(X_test, X_train)\n",
    "    idx_mink = np.argpartition(dists, k, axis=1)[:, :k]\n",
    "\n",
    "    if task == \"class\":\n",
    "        labels_mink = y_train[idx_mink]\n",
    "        maj_labels = np.zeros(labels_mink.shape[0], dtype=np.bool)\n",
    "        for i, row in enumerate(labels_mink):\n",
    "            values, counts = np.unique(row, return_counts=True)\n",
    "            maj_labels[i] = values[np.argmax(counts)]\n",
    "        return maj_labels\n",
    "    else:  # regression\n",
    "        return X_train[idx_mink].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0b52a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_predict(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c345ca9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d820b164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnClf = KNeighborsClassifier(n_neighbors=5)\n",
    "knnClf.fit(X_train, y_train)\n",
    "knnClf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c017d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total_raw = df[\"Total\"].to_numpy().reshape((-1, 1))\n",
    "y_total = ss.fit_transform(y_total_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3029ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_regr = knn_predict(X_train, y_total, X_test, task=\"regr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594b5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 6)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnRegr = KNeighborsRegressor(n_neighbors=5)\n",
    "knnRegr.fit(X_train, y_total)\n",
    "knnRegr.predict(y_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
